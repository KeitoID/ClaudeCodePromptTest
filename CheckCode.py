#!/usr/bin/env python3
"""
è¨€èªåˆ¥ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã®PEP 8æº–æ‹ åº¦ã‚’æ¤œè¨¼ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ä½¿ç”¨ãƒ„ãƒ¼ãƒ«: flake8 (with extensions), pylint
"""

import subprocess
import json
import os
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import re

class CodeQualityChecker:
    """ã‚³ãƒ¼ãƒ‰å“è³ªã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, code_directory: str):
        """
        Args:
            code_directory: æ¤œè¨¼å¯¾è±¡ã®ã‚³ãƒ¼ãƒ‰ãŒæ ¼ç´ã•ã‚Œã¦ã„ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        """
        self.code_dir = Path(code_directory)
        self.results = {}
        
        # flake8ã®ã‚¨ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‰åˆ†é¡
        self.error_categories = {
            'E': 'PEP 8 errors',
            'W': 'PEP 8 warnings', 
            'F': 'PyFlakes errors',
            'C': 'Complexity',
            'D': 'Docstring issues',
            'TC': 'Type checking issues',
            'N': 'Naming conventions'
        }
    
    def check_flake8_with_extensions(self, filepath: str) -> Dict:
        """
        flake8ã§PEP 8æº–æ‹ ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆæ‹¡å¼µæ©Ÿèƒ½ä»˜ãï¼‰
        - flake8-docstrings: docstringã®ãƒã‚§ãƒƒã‚¯
        - flake8-type-checking: å‹ãƒã‚§ãƒƒã‚¯é–¢é€£
        """
        try:
            # flake8ã‚’å®Ÿè¡Œï¼ˆæ‹¡å¼µæ©Ÿèƒ½ã¯è‡ªå‹•çš„ã«æœ‰åŠ¹ã«ãªã‚‹ï¼‰
            result = subprocess.run(
                [
                    'flake8',
                    '--statistics',
                    '--count',
                    '--show-source',  # ã‚¨ãƒ©ãƒ¼ç®‡æ‰€ã®ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‚’è¡¨ç¤º
                    '--max-line-length=88',  # Blackã‚¹ã‚¿ã‚¤ãƒ«ã®è¡Œé•·
                    filepath
                ],
                capture_output=True,
                text=True
            )
            
            # çµæœã®è§£æ
            issues = []
            statistics = {}
            total_errors = 0
            errors_by_category = {}
            
            # å„è¡Œã‚’è§£æ
            lines = result.stdout.split('\n')
            for line in lines:
                if not line.strip():
                    continue
                
                # ãƒ•ã‚¡ã‚¤ãƒ«å:è¡Œ:åˆ—: ã‚¨ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‰ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ ã®å½¢å¼ã‚’è§£æ
                match = re.match(r'.*:(\d+):(\d+):\s+([A-Z]+\d+)\s+(.*)', line)
                if match:
                    line_num, col_num, error_code, message = match.groups()
                    issues.append({
                        'line': int(line_num),
                        'column': int(col_num),
                        'code': error_code,
                        'message': message,
                        'category': self._categorize_error(error_code)
                    })
                    total_errors += 1
                    
                    # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«ã‚«ã‚¦ãƒ³ãƒˆ
                    category = self._categorize_error(error_code)
                    errors_by_category[category] = errors_by_category.get(category, 0) + 1
            
            # çµ±è¨ˆæƒ…å ±ã®è§£æï¼ˆæ¨™æº–ã‚¨ãƒ©ãƒ¼å‡ºåŠ›ã‹ã‚‰ï¼‰
            stderr_lines = result.stderr.split('\n')
            for line in stderr_lines:
                parts = line.strip().split()
                if len(parts) >= 2 and parts[0].isdigit():
                    count = int(parts[0])
                    code = parts[1]
                    statistics[code] = count
            
            return {
                'tool': 'flake8',
                'total_issues': total_errors,
                'issues': issues[:10],  # æœ€åˆã®10ä»¶ã®ã¿è©³ç´°ã‚’ä¿å­˜
                'errors_by_category': errors_by_category,
                'statistics': statistics,
                'has_docstring_issues': 'Docstring issues' in errors_by_category,
                'has_type_checking_issues': 'Type checking issues' in errors_by_category,
                'exit_code': result.returncode
            }
            
        except FileNotFoundError:
            return {
                'tool': 'flake8',
                'error': 'flake8 not installed. Please run: pip install flake8 flake8-docstrings flake8-type-checking'
            }
        except Exception as e:
            return {'tool': 'flake8', 'error': str(e)}
    
    def _categorize_error(self, error_code: str) -> str:
        """ã‚¨ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‰ã‚’ã‚«ãƒ†ã‚´ãƒªã«åˆ†é¡"""
        if error_code.startswith('E'):
            return 'PEP 8 errors'
        elif error_code.startswith('W'):
            return 'PEP 8 warnings'
        elif error_code.startswith('F'):
            return 'PyFlakes errors'
        elif error_code.startswith('C'):
            return 'Complexity'
        elif error_code.startswith('D'):
            return 'Docstring issues'
        elif error_code.startswith('TC'):
            return 'Type checking issues'
        elif error_code.startswith('N'):
            return 'Naming conventions'
        else:
            return 'Other'
    
    def check_pylint(self, filepath: str) -> Dict:
        """pylintã§ãƒã‚§ãƒƒã‚¯ï¼ˆè©³ç´°ãªè§£æï¼‰"""
        try:
            result = subprocess.run(
                [
                    'pylint',
                    '--output-format=json',  # JSONå½¢å¼ã§å‡ºåŠ›
                    filepath
                ],
                capture_output=True,
                text=True
            )
            
            # ã‚¹ã‚³ã‚¢ã‚’å–å¾—ã™ã‚‹ãŸã‚ã«é€šå¸¸å½¢å¼ã§ã‚‚å®Ÿè¡Œ
            score_result = subprocess.run(
                ['pylint', '--score=y', filepath],
                capture_output=True,
                text=True
            )
            
            # ã‚¹ã‚³ã‚¢ã‚’æŠ½å‡º
            score = None
            for line in score_result.stdout.split('\n'):
                if 'Your code has been rated at' in line:
                    score_match = re.search(r'([-\d.]+)/10', line)
                    if score_match:
                        score = float(score_match.group(1))
            
            # JSONçµæœã‚’è§£æ
            issues_by_type = {
                'convention': 0,
                'refactor': 0,
                'warning': 0,
                'error': 0,
                'fatal': 0,
                'info': 0
            }
            
            message_types = {}
            
            try:
                issues = json.loads(result.stdout) if result.stdout else []
                for issue in issues:
                    issue_type = issue.get('type', 'unknown')
                    if issue_type in issues_by_type:
                        issues_by_type[issue_type] += 1
                    
                    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸IDã”ã¨ã«ã‚«ã‚¦ãƒ³ãƒˆ
                    msg_id = issue.get('message-id', 'unknown')
                    message_types[msg_id] = message_types.get(msg_id, 0) + 1
            except json.JSONDecodeError:
                issues = []
            
            return {
                'tool': 'pylint',
                'score': score,
                'issues_by_type': issues_by_type,
                'total_issues': sum(issues_by_type.values()),
                'message_types': dict(sorted(message_types.items(), key=lambda x: x[1], reverse=True)[:10]),  # ä¸Šä½10ä»¶
                'has_errors': issues_by_type.get('error', 0) > 0,
                'has_warnings': issues_by_type.get('warning', 0) > 0
            }
            
        except FileNotFoundError:
            return {
                'tool': 'pylint',
                'error': 'pylint not installed. Please run: pip install pylint'
            }
        except Exception as e:
            return {'tool': 'pylint', 'error': str(e)}
    
    def analyze_code_structure(self, filepath: str) -> Dict:
        """ã‚³ãƒ¼ãƒ‰æ§‹é€ ã®åˆ†æï¼ˆå‹ãƒ’ãƒ³ãƒˆã€docstringã€etcï¼‰"""
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                content = f.read()
                lines = content.split('\n')
            
            analysis = {
                'total_lines': len(lines),
                'code_lines': 0,
                'comment_lines': 0,
                'docstring_lines': 0,
                'blank_lines': 0,
                'functions': [],
                'classes': [],
                'has_type_hints': False,
                'has_module_docstring': False,
                'imports_count': 0,
                'type_annotations_count': 0
            }
            
            # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ¬ãƒ™ãƒ«ã®docstringãƒã‚§ãƒƒã‚¯
            stripped_content = content.strip()
            if stripped_content.startswith('"""') or stripped_content.startswith("'''"):
                analysis['has_module_docstring'] = True
            
            in_docstring = False
            docstring_quotes = None
            
            for i, line in enumerate(lines):
                stripped = line.strip()
                
                # ç©ºè¡Œã®åˆ¤å®šã‚’ä¿®æ­£ï¼šå®Ÿéš›ã«ç©ºç™½ã®ã¿ã®è¡Œã‹ãƒã‚§ãƒƒã‚¯
                if not stripped:
                    analysis['blank_lines'] += 1
                    continue
                
                # docstringå‡¦ç†
                if '"""' in stripped or "'''" in stripped:
                    quotes = '"""' if '"""' in stripped else "'''"
                    if not in_docstring:
                        in_docstring = True
                        docstring_quotes = quotes
                        analysis['docstring_lines'] += 1
                    elif quotes == docstring_quotes:
                        in_docstring = False
                        analysis['docstring_lines'] += 1
                    continue
                
                if in_docstring:
                    analysis['docstring_lines'] += 1
                    continue
                
                # ã‚³ãƒ¡ãƒ³ãƒˆè¡Œã®åˆ¤å®šã‚’ä¿®æ­£
                if stripped.startswith('#'):
                    analysis['comment_lines'] += 1
                    continue
                
                # ã“ã“ã¾ã§æ¥ãŸã‚‰ã‚³ãƒ¼ãƒ‰è¡Œ
                analysis['code_lines'] += 1
                
                # importæ–‡
                if stripped.startswith('import ') or stripped.startswith('from '):
                    analysis['imports_count'] += 1
                
                # é–¢æ•°å®šç¾©ï¼ˆå‹ãƒ’ãƒ³ãƒˆä»˜ãã‹ãƒã‚§ãƒƒã‚¯ï¼‰
                if stripped.startswith('def '):
                    func_match = re.match(r'def\s+(\w+)\s*\((.*?)\)', stripped)
                    if func_match:
                        func_name = func_match.group(1)
                        params = func_match.group(2)
                        has_type_hint = '->' in line or ':' in params
                        analysis['functions'].append({
                            'name': func_name,
                            'line': i + 1,
                            'has_type_hints': has_type_hint
                        })
                        if has_type_hint:
                            analysis['has_type_hints'] = True
                            analysis['type_annotations_count'] += 1
                
                # ã‚¯ãƒ©ã‚¹å®šç¾©
                if stripped.startswith('class '):
                    class_match = re.match(r'class\s+(\w+)', stripped)
                    if class_match:
                        analysis['classes'].append({
                            'name': class_match.group(1),
                            'line': i + 1
                        })
                
                # å¤‰æ•°ã®å‹ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
                if re.search(r':\s*(int|str|float|bool|List|Dict|Tuple|Optional|Any|Union)', line):
                    analysis['type_annotations_count'] += 1
                    analysis['has_type_hints'] = True
            
            # æ¯”ç‡è¨ˆç®—
            if analysis['total_lines'] > 0:
                analysis['comment_ratio'] = (analysis['comment_lines'] + analysis['docstring_lines']) / analysis['total_lines']
                analysis['code_ratio'] = analysis['code_lines'] / analysis['total_lines']
            else:
                analysis['comment_ratio'] = 0
                analysis['code_ratio'] = 0
            
            return analysis
            
        except Exception as e:
            return {'error': str(e)}
    
    def check_file(self, filepath: str) -> Dict:
        """å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã®å®Œå…¨ãƒã‚§ãƒƒã‚¯"""
        full_path = self.code_dir / filepath if not Path(filepath).is_absolute() else Path(filepath)
        
        if not full_path.exists():
            return {'error': f'File not found: {filepath}'}
        
        return {
            'filename': filepath,
            'flake8': self.check_flake8_with_extensions(str(full_path)),
            'pylint': self.check_pylint(str(full_path)),
            'structure': self.analyze_code_structure(str(full_path))
        }
    
    def check_all_files(self, language_patterns: Dict[str, List[str]]) -> Dict:
        """
        è¨€èªãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥ã«ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯
        
        Args:
            language_patterns: {'en': ['file1.py', ...], 'ja': [...], 'mixed': [...]}
        """
        results = {}
        
        for lang, files in language_patterns.items():
            results[lang] = []
            for filepath in files:
                print(f"Checking {lang}/{filepath}...")
                file_result = self.check_file(filepath)
                results[lang].append(file_result)
        
        return results
    
    def generate_comparison_report(self, results: Dict) -> str:
        """è©³ç´°ãªæ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
        report = []
        report.append("=" * 70)
        report.append("Code Quality Comparison Report")
        report.append("Tools: flake8 (with docstrings & type-checking), pylint")
        report.append("=" * 70)
        
        summary_data = {}
        
        for lang in results:
            report.append(f"\n### Language Pattern: {lang.upper()}")
            report.append("-" * 50)
            
            # è¨€èªåˆ¥ã®é›†è¨ˆ
            lang_summary = {
                'flake8_total': 0,
                'flake8_categories': {},
                'pylint_scores': [],
                'pylint_issues': 0,
                'has_docstrings': 0,
                'has_type_hints': 0,
                'avg_comment_ratio': 0,
                'files_count': len(results[lang])
            }
            
            for file_result in results[lang]:
                # flake8çµæœã®é›†è¨ˆ
                if 'flake8' in file_result and 'total_issues' in file_result['flake8']:
                    lang_summary['flake8_total'] += file_result['flake8']['total_issues']
                    
                    # ã‚«ãƒ†ã‚´ãƒªåˆ¥é›†è¨ˆ
                    for category, count in file_result['flake8'].get('errors_by_category', {}).items():
                        lang_summary['flake8_categories'][category] = \
                            lang_summary['flake8_categories'].get(category, 0) + count
                
                # pylintçµæœã®é›†è¨ˆ
                if 'pylint' in file_result:
                    pylint_data = file_result['pylint']
                    if 'score' in pylint_data and pylint_data['score'] is not None:
                        lang_summary['pylint_scores'].append(pylint_data['score'])
                    if 'total_issues' in pylint_data:
                        lang_summary['pylint_issues'] += pylint_data['total_issues']
                
                # æ§‹é€ åˆ†æã®é›†è¨ˆ
                if 'structure' in file_result and 'error' not in file_result['structure']:
                    structure = file_result['structure']
                    if structure.get('has_module_docstring'):
                        lang_summary['has_docstrings'] += 1
                    if structure.get('has_type_hints'):
                        lang_summary['has_type_hints'] += 1
                    lang_summary['avg_comment_ratio'] += structure.get('comment_ratio', 0)
            
            # å¹³å‡å€¤è¨ˆç®—
            if lang_summary['files_count'] > 0:
                lang_summary['avg_comment_ratio'] /= lang_summary['files_count']
                if lang_summary['pylint_scores']:
                    lang_summary['avg_pylint_score'] = sum(lang_summary['pylint_scores']) / len(lang_summary['pylint_scores'])
                else:
                    lang_summary['avg_pylint_score'] = 0
            
            # ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›
            report.append(f"\nğŸ“Š Summary for {lang.upper()}:")
            report.append(f"  Files analyzed: {lang_summary['files_count']}")
            
            report.append(f"\n  Flake8 Results:")
            report.append(f"    Total issues: {lang_summary['flake8_total']}")
            if lang_summary['flake8_categories']:
                report.append(f"    Issues by category:")
                for category, count in sorted(lang_summary['flake8_categories'].items()):
                    report.append(f"      - {category}: {count}")
            
            report.append(f"\n  Pylint Results:")
            report.append(f"    Average score: {lang_summary['avg_pylint_score']:.2f}/10.0")
            report.append(f"    Total issues: {lang_summary['pylint_issues']}")
            
            report.append(f"\n  Code Quality Metrics:")
            report.append(f"    Files with module docstrings: {lang_summary['has_docstrings']}/{lang_summary['files_count']}")
            report.append(f"    Files with type hints: {lang_summary['has_type_hints']}/{lang_summary['files_count']}")
            report.append(f"    Average comment ratio: {lang_summary['avg_comment_ratio']:.1%}")
            
            summary_data[lang] = lang_summary
        
        # æ¯”è¼ƒã‚µãƒãƒªãƒ¼
        report.append("\n" + "=" * 70)
        report.append("COMPARATIVE ANALYSIS")
        report.append("=" * 70)
        
        if len(summary_data) > 1:
            # æœ€è‰¯ã®ã‚¹ã‚³ã‚¢ã‚’æŒã¤è¨€èªã‚’ç‰¹å®š
            best_pylint = max(summary_data.items(), key=lambda x: x[1].get('avg_pylint_score', 0))
            least_issues = min(summary_data.items(), key=lambda x: x[1]['flake8_total'])
            
            report.append(f"\nğŸ† Best Practices:")
            report.append(f"  Highest Pylint score: {best_pylint[0]} ({best_pylint[1]['avg_pylint_score']:.2f}/10)")
            report.append(f"  Fewest flake8 issues: {least_issues[0]} ({least_issues[1]['flake8_total']} issues)")
            
            # è©³ç´°ãªæ¯”è¼ƒ
            report.append(f"\nğŸ“ˆ Detailed Comparison:")
            langs = list(summary_data.keys())
            
            # PEP 8æº–æ‹ åº¦ã®æ¯”è¼ƒ
            report.append(f"\n  PEP 8 Compliance (flake8 issues - lower is better):")
            for lang in langs:
                issues_per_file = summary_data[lang]['flake8_total'] / summary_data[lang]['files_count'] if summary_data[lang]['files_count'] > 0 else 0
                report.append(f"    {lang}: {issues_per_file:.1f} issues/file")
            
            # Docstringä½¿ç”¨ç‡ã®æ¯”è¼ƒ
            report.append(f"\n  Documentation Quality:")
            for lang in langs:
                doc_ratio = summary_data[lang]['has_docstrings'] / summary_data[lang]['files_count'] if summary_data[lang]['files_count'] > 0 else 0
                report.append(f"    {lang}: {doc_ratio:.0%} files with module docstrings")
            
            # å‹ãƒ’ãƒ³ãƒˆä½¿ç”¨ç‡ã®æ¯”è¼ƒ
            report.append(f"\n  Type Safety:")
            for lang in langs:
                type_ratio = summary_data[lang]['has_type_hints'] / summary_data[lang]['files_count'] if summary_data[lang]['files_count'] > 0 else 0
                report.append(f"    {lang}: {type_ratio:.0%} files with type hints")
        
        report.append("\n" + "=" * 70)
        return "\n".join(report)


# ä½¿ç”¨ä¾‹
if __name__ == "__main__":
    import sys
    
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‹ã‚‰ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å–å¾—ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯"output"ï¼‰
    code_dir = sys.argv[1] if len(sys.argv) > 1 else "Output"
    
    print(f"Checking code quality in directory: {code_dir}")
    checker = CodeQualityChecker(code_dir)
    
    language_patterns = {
        'en': ['binary_search_tree_en.py'],
        'ja': ['binary_search_tree_Ja.py'],
        'mixed': ['binary_search_tree_mix.py'],
    }
    
    # å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ†ã‚¹ãƒˆç”¨
    # single_result = checker.check_file('test.py')
    # print(json.dumps(single_result, indent=2, ensure_ascii=False))
    
    # è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ
    print("\nRunning quality checks...")
    results = checker.check_all_files(language_patterns)
    
    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã¨è¡¨ç¤º
    report = checker.generate_comparison_report(results)
    print(report)
    
    # è©³ç´°çµæœã‚’JSONå½¢å¼ã§ä¿å­˜
    output_file = 'code_quality_results.json'
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    print(f"\nDetailed results saved to: {output_file}")